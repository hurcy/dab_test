# DAB Test Project

A comprehensive monorepo demonstrating Databricks Asset Bundle (DAB) patterns, featuring shared utilities, configuration management, and CI/CD best practices for Databricks environments. This project showcases enterprise-grade development workflows for data applications.

## ğŸ—ï¸ Repository Structure

```
dab_test/
â”œâ”€â”€ common_framework/           # Shared utility framework
â”‚   â”œâ”€â”€ config/                 # Configuration files
â”‚   â”‚   â”œâ”€â”€ bar.yml            # YAML configuration
â”‚   â”‚   â””â”€â”€ data.json          # JSON data
â”‚   â”œâ”€â”€ src/zoo/               # Utility modules
â”‚   â”œâ”€â”€ tests/                 # Framework tests
â”‚   â”œâ”€â”€ pytest.ini            # Pytest configuration
â”‚   â””â”€â”€ README.md              # Framework documentation
â”œâ”€â”€ dab_demo/                  # Main DAB demonstration project
â”‚   â”œâ”€â”€ src/                   # Application source code
â”‚   â”‚   â”œâ”€â”€ foo/               # Example modules
â”‚   â”‚   â”œâ”€â”€ helpers/           # PySpark utility functions
â”‚   â”‚   â”œâ”€â”€ path_manager.py    # Path management utility
â”‚   â”‚   â”œâ”€â”€ session_manager.py # Spark session management
â”‚   â”‚   â””â”€â”€ *.ipynb           # Demonstration notebooks
â”‚   â”œâ”€â”€ tests/                 # Application tests
â”‚   â”‚   â”œâ”€â”€ helpers/           # Helper function tests
â”‚   â”‚   â”œâ”€â”€ conftest.py        # Pytest configuration
â”‚   â”‚   â””â”€â”€ test_*.py         # Test modules
â”‚   â”œâ”€â”€ resources/             # DAB resources
â”‚   â”œâ”€â”€ scratch/               # Development workspace
â”‚   â”œâ”€â”€ fixtures/              # Test fixtures
â”‚   â”œâ”€â”€ databricks.yml        # DAB configuration
â”‚   â”œâ”€â”€ requirements-dev.txt   # Development dependencies
â”‚   â””â”€â”€ README.md              # Project documentation
â”œâ”€â”€ LICENSE                    # Project license
â”œâ”€â”€ .gitignore                 # Git ignore rules
â””â”€â”€ README.md                  # This file
```

## ğŸš€ Project Overview

### **Common Framework**
A shared library providing:
- **Configuration Management**: YAML/JSON configuration handling with validation
- **Utility Functions**: Reusable mathematical and data processing utilities
- **Data Pipelines**: Delta Live Tables integration for data processing
- **Testing Infrastructure**: Comprehensive pytest-based testing framework

### **DAB Demo**
A production-ready Databricks Asset Bundle showcasing:
- **Path Management**: Singleton-based path resolution across environments
- **Session Management**: Optimized Spark session configuration with logging control
- **PySpark Utilities**: Helper functions for DataFrame operations and column manipulation
- **Testing Framework**: Comprehensive testing with chispa integration and pytest fixtures
- **Smart Configuration**: Environment-aware setup for notebooks and modules
- **CI/CD Patterns**: Multi-environment deployment with Bundle configuration

## ğŸ¯ Key Features

### **Monorepo Architecture**
- **Shared Dependencies**: Common framework used across multiple projects
- **Synchronized Deployment**: Bundle configuration deploys both projects together
- **Cross-Project Integration**: Seamless module sharing and path resolution

### **Environment Management**
- **Multi-Environment Support**: Development and production configurations
- **Path Resolution**: Intelligent handling of local vs. Bundle environments
- **Configuration Validation**: Automated testing of configuration integrity

### **Testing Excellence**
- **Comprehensive Coverage**: Unit tests for all modules and configurations
- **PySpark Testing**: Advanced DataFrame testing with chispa library
- **Pytest Integration**: Custom fixtures and configuration for Spark testing
- **Helper Function Testing**: Validation of column operations and DataFrame utilities
- **Databricks Integration**: Native testing within Databricks notebooks
- **CI/CD Ready**: Automated testing in deployment pipelines

### **Developer Experience**
- **Smart Path Setup**: Automatic `sys.path` configuration for notebooks
- **Error Resilience**: Robust error handling and fallback strategies
- **Documentation**: Comprehensive guides in both English and Korean

## ğŸš€ Quick Start

### **Prerequisites**
```bash
# Install Databricks CLI
pip install databricks-cli

# Authenticate to workspace
databricks configure
```

### **Local Development**
```bash
# Clone and setup
git clone <repository-url>
cd dab_test

# Install dependencies
pip install -r dab_demo/requirements-dev.txt

# Run tests
cd common_framework && pytest
cd ../dab_demo && pytest
```

### **Databricks Deployment**
```bash
# Deploy to development
cd dab_demo
databricks bundle deploy --target dev

# Run jobs
databricks bundle run dab_demo_job --target dev

# Deploy to production
databricks bundle deploy --target prod
```

## ğŸ§ª Testing Strategy

### **Local Testing**
```bash
# Test common framework
cd common_framework
pytest tests/ -v

# Test main application
cd dab_demo
pytest tests/ -v --cov=src
```

### **Databricks Testing**
- Use `dab_demo/tests/pytest_runner.ipynb` for in-platform testing
- Automated test execution within Databricks environment
- Integration testing with actual Databricks resources

## ğŸ“‹ Configuration Management

### **Common Framework Config**
- `common_framework/config/bar.yml`: Structured YAML configuration
- `common_framework/config/data.json`: JSON data arrays
- Automated validation through pytest

### **DAB Configuration**
- `dab_demo/databricks.yml`: Multi-environment Bundle configuration
- Resource definitions and job orchestration
- Monorepo synchronization settings

## ğŸ› ï¸ Development Workflow

### **1. Local Development**
- Write and test code locally using pytest
- Use PathResolver for consistent file access
- Validate configurations before deployment

### **2. Bundle Deployment**
- Deploy to development environment for integration testing
- Run comprehensive test suites in Databricks
- Validate job execution and resource access

### **3. Production Release**
- Deploy to production after thorough validation
- Monitor job execution and performance
- Maintain configuration integrity

## ğŸ“š Project Components

### **Common Framework Components**
- **Zoo Utilities** (`src/zoo/`): Mathematical and data processing functions
- **Configuration System**: YAML/JSON handling with validation
- **DLT Pipeline**: Delta Live Tables integration
- **Test Suite**: Comprehensive validation framework

### **DAB Demo Components**
- **Path Manager**: Singleton pattern for environment-aware path resolution
- **Configuration Reader**: YAML configuration integration with common framework
- **Notebook Utilities**: Smart path setup and module import helpers
- **Job Definitions**: Databricks Workflows and resource management

## ğŸ”§ Advanced Features

### **Cross-Project Integration**
```python
# In dab_demo, access common_framework resources
from path_manager import PathResolver
from foo.bar import parse_bar

paths = PathResolver()
config_data = parse_bar()  # Reads from common_framework/config/bar.yml
```

### **Environment Detection**
```python
# Smart environment handling
%run ./set_notebook_paths  # In Databricks notebooks

# Automatic path configuration based on environment
# - Local development
# - Databricks Bundle
# - User workspace
```

### **Robust Error Handling**
- File encoding detection and handling
- Bundle vs. source path resolution
- Graceful fallback strategies

## ğŸ“– Documentation

- **[Common Framework](./common_framework/README.md)**: Detailed framework documentation
- **[DAB Demo](./dab_demo/README.md)**: Complete project guide
- **[Databricks Asset Bundles](https://docs.databricks.com/dev-tools/bundles/index.html)**: Official DAB documentation

## ğŸ¤ Contributing

1. **Fork the repository** and create a feature branch
2. **Develop locally** with comprehensive testing
3. **Test in both projects** (common_framework and dab_demo)
4. **Validate Bundle deployment** in development environment
5. **Submit pull request** with clear documentation

## ğŸ” Common Issues & Solutions

### **Import Errors**
```python
# Solution: Use notebook path setup
%run ./set_notebook_paths
```

### **Bundle Path Issues**
- Prefer original source paths over `.bundle` paths
- Use PathResolver for consistent path handling

### **Configuration Problems**
- Validate YAML/JSON syntax with pytest
- Check file permissions and encoding

### **Deployment Failures**
```bash
# Validate configuration
databricks bundle validate

# Check authentication
databricks auth profiles
```

## ğŸ“Š Project Metrics

- **2 Main Projects**: common_framework + dab_demo
- **Comprehensive Testing**: 100% configuration validation coverage
- **Multi-Environment**: Development and production ready
- **Cross-Platform**: Local development + Databricks deployment
- **Documentation**: English + Korean language support

## ğŸ¯ Use Cases

### **Data Engineering Teams**
- Shared utility libraries across multiple projects
- Standardized configuration management
- Consistent deployment patterns

### **MLOps Workflows**
- Model training and deployment pipelines
- Environment-specific configuration handling
- Automated testing and validation

### **Enterprise Development**
- Multi-project monorepo management
- CI/CD pipeline integration
- Cross-team collaboration patterns

---

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ·ï¸ Tags

`databricks` `asset-bundles` `python` `pytest` `monorepo` `ci-cd` `data-engineering` `mlops` `configuration-management` `path-resolution`
